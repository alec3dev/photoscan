<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Face Crop with RotationNNNN</title>
  <script src="https://cdn.jsdelivr.net/npm/exif-js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    #output img {margin:5px; border:1px solid #ccc;}
  </style>
</head>
<body>
<input type="file" id="fileInput">
<div id="output"></div>

<script>
async function loadModels() {
  await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
  await faceapi.nets.faceLandmark68TinyNet.loadFromUri('/models');
}

function correctImageRotation(img) {
  return new Promise((resolve) => {
    EXIF.getData(img, function() {
      const orientation = EXIF.getTag(this, 'Orientation') || 1;
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      let width = img.width;
      let height = img.height;
      let rotate = 0;

      if (orientation === 3) rotate = 180;
      if (orientation === 6) rotate = 90;
      if (orientation === 8) rotate = 270;

      if (rotate === 90 || rotate === 270) {
        canvas.width = height;
        canvas.height = width;
      } else {
        canvas.width = width;
        canvas.height = height;
      }

      ctx.translate(canvas.width/2, canvas.height/2);
      ctx.rotate(rotate * Math.PI / 180);
      ctx.drawImage(img, -width/2, -height/2);
      const newImg = new Image();
      newImg.onload = () => resolve(newImg);
      newImg.src = canvas.toDataURL();
    });
  });
}

async function detectAndCrop(img) {
  const detections = await faceapi.detectAllFaces(img, new faceapi.TinyFaceDetectorOptions())
                                   .withFaceLandmarks(true);

  const output = document.getElementById('output');
  output.innerHTML = '';

  for (const det of detections) {
    // bounding box
    const box = det.detection.box;
    const landmarks = det.landmarks;
    const leftEye = landmarks.getLeftEye();
    const rightEye = landmarks.getRightEye();

    // compute angle between eyes
    const dx = rightEye[0].x - leftEye[0].x;
    const dy = rightEye[0].y - leftEye[0].y;
    const angle = Math.atan2(dy, dx);

    // crop face region
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    canvas.width = box.width;
    canvas.height = box.height;

    // rotate context so eyes become horizontal
    ctx.translate(canvas.width/2, canvas.height/2);
    ctx.rotate(-angle);
    ctx.drawImage(
      img,
      box.x, box.y, box.width, box.height,
      -box.width/2, -box.height/2, box.width, box.height
    );

    const croppedImg = new Image();
    croppedImg.src = canvas.toDataURL('image/jpeg');
    output.appendChild(croppedImg);
  }
}

document.getElementById('fileInput').addEventListener('change', async (e) => {
  const file = e.target.files[0];
  const img = new Image();
  img.onload = async () => {
    const corrected = await correctImageRotation(img);
    await detectAndCrop(corrected);
  };
  img.src = URL.createObjectURL(file);
});

loadModels();
</script>
</body>
</html>
